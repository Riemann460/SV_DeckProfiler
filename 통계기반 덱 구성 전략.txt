🧠 핵심 이론: '분산(Variance)'을 '덱 빌딩'으로 번역하는 법
우리의 목표는 '평균 덱'을 제시하는 것이 아닙니다. '가중 평균'과 '분산'이라는 2차원 데이터를 통해 **"이 덱의 '뼈대(고정칸)'는 무엇이며, 환경에 따라 바뀌는 '살(선택칸)'은 무엇인가"**를 사용자에게 제안하는 것입니다.

'분산'은 "이 카드 채용 매수에 대해 데이터 제공자(유저)들 간의 '의견 일치도'"를 의미합니다.

분산이 낮다 (Low Variance):
의미: 의견 일치도가 높다.
번역: "모든 유저가 이 카드를 3장(혹은 0장) 쓴다."
적용: 덱의 '뼈대'이자 '핵심'. 즉, **'고정칸(Core Slot)'**의 강력한 후보입니다.

분산이 높다 (High Variance):
의미: 의견 일치도가 낮다. (누군 0장, 누군 1장, 누군 3장)
번역: "이 카드는 환경, 취향, 특정 매치업에 따라 조절하는 카드다."
적용: 덱의 '살'이자 '기술'. 즉, **'선택칸(Flex Slot)'**이자 **'교체 후보'**입니다.

⚙️ 시스템 적용 1: '고정칸' (채용카드) 선정 로직
'고정칸'은 평균과 분산 두 가지 데이터를 모두 충족해야 합니다.

[조건 1] 가중 평균 (Average): 특정 정수에 가까워야 합니다. 
[조건 2] 분산 (Variance): 낮아야 합니다.
[로직 구현 (예시)]
if (abs(delta) < 0.28 AND variance < 0.3): card.type = '고정칸'

⚙️ 시스템 적용 2: '선택칸' (교체후보) 선정 및 40장 조정 로직
이것이 M9 (40장 조정) 로직을 '수학적 오차' 기반에서 '전략적 중요도' 기반으로 고도화하는 핵심입니다.

1. '선택칸'의 정의: '선택칸'은 '분산'이 높은 카드입니다. (평균은 0.5일 수도, 1.5일 수도 있습니다. 중요한 것은 분산입니다.)

2. 고도화된 40장 조정 로직
기존 로직 (M9): '평균과의 거리(delta)'가 가장 큰 카드를 1장씩 줄였습니다. (수학적 오차 기반)
신규 로직 (M11):
🧠 1. 핵심 이론: 벡터 공간과 포트폴리오 최적화Riemann님은 지금 'N차원 벡터 공간'에서 '덱'을 분석하고 있습니다.
**모든 카드(N개)**는 하나의 차원(Dimension)입니다.
평균 덱 (Average Vector): V_avg = (avg_c1, avg_c2, ...)
최종 덱 (Final Deck Vector): V_final = (final_c1, final_c2, ...) (여기서 final_c는 0, 1, 2, 3...)
분산 벡터 (Variance Vector): V_var = (var_c1, var_c2, ...)(말씀하신 대로 '제곱근 벡터', 즉 **표준편차 벡터 V_std_dev**를 쓰는 것이 단위(Unit)를 맞추는 데 더 직관적입니다.)
1-A. 델타 벡터 (The "Delta Vector")
정의: V_delta = V_final - V_avg
의미: 최종 덱이 '평균'으로부터 '얼마나, 그리고 어느 방향으로' 벗어났는지를 나타내는 벡터입니다.
1-B. 표준편차 벡터 (The "Risk Profile Vector")
정의: V_std_dev = (std_c1, std_c2, ...)
의미: 각 카드가 '자연스럽게 변동하는' 크기(위험)의 프로필입니다. 표준편차가 큰 카드는 '변동이 허용된' 카드입니다.
1-C. Riemann님의 최적화 목표: 코사인 유사도 (Cosine Similarity)"델타벡터의 방향이 분산벡터의 방향과 가장 가깝도록"
이것은 두 벡터의 '방향성'이 얼마나 일치하는지를 측정하는 **'코사인 유사도(Cosine Similarity)'**를 최대화하는 문제로 완벽하게 정의됩니다.
목표: Maximize ( Cosine_Similarity(V_delta, V_std_dev) )
왜 이 목표가 훌륭한가?
V_delta (최종 덱의 '편차')가V_std_dev ('자연스러운 변동성')가 허용된 방향과일치하게 만듭니다.
번역: "평균에서 벗어날 수밖에 없다면 (42장 $\rightarrow$ 40장), '원래 변동이 심한(분산이 큰)' 카드들 위주로 조절하여, '핵심 뼈대(분산이 낮은)'는 건드리지 않는 가장 자연스러운 덱을 만들겠다."

⚙️ 2. 로직 설계: "완벽한 탐색"의 함정과 "실행 가능한 휴리스틱"
이 문제는 본질적으로 "제약 조건이 있는 조합 최적화(Constrained Combinatorial Optimization)" 문제입니다.
제약: sum(V_final) == 40
목표: Cosine_Similarity 최대화
[위험 1: 완벽한 탐색 (The Perfection Trap)]모든 40장 조합을 탐색하는 것은 '내전(광기)' 3을 일으키는 '완벽주의' 4입니다. (NP-Hard 문제입니다)
[위험 2: 단순한 탐욕 (The Simple Greedy)]'분산이 가장 큰 카드' 2장을 즉시 제거하는 것은, Riemann님이 지적했듯 덱 '전체'의 균형을 고려하지 못합니다.
[시스템 아키텍처 M11: '점진적 휴리스틱' (Greedy Heuristic)]'스탠퍼드 도자기 실험' 5처럼, '완벽한 1개'를 찾는 것이 아니라 '실행 가능한' 알고리즘으로 '점진적으로 완성'합니다.우리의 전략은 '기준 덱'(42장)에서 시작하여, '코사인 유사도'를 가장 적게 훼손하는(혹은 가장 많이 개선하는) 카드를 '탐욕적으로' 하나씩 제거하는 것입니다.
[기준 설정]V_avg (평균 벡터)와 V_std_dev (표준편차 벡터)를 계산합니다.'기준 덱' V_current를 rounded_average (반올림) 값으로 생성합니다. (e.g., 총합 42장)현재 줄여야 할 매수 cards_to_cut = 2를 설정합니다.
[후보군 식별]'제거 후보군'을 식별합니다. 
(e.g., V_current에서 1장 이상 사용된 모든 카드)
[탐욕 알고리즘 루프 (Greedy Loop)]
while (cards_to_cut > 0):
best_card_to_cut = None
max_similarity = -Infinity (최악의 값으로 초기화)
[Inner Loop: 모든 '후보 카드 C'에 대해 시뮬레이션]
V_temp = V_current.copy()
V_temp[C] -= 1 (C번 카드를 1장 '임시로' 제거)
V_temp_delta = V_temp - V_avg (임시 델타 벡터 계산)
temp_similarity = Cosine_Similarity(V_temp_delta, V_std_dev) (임시 코사인 유사도 계산)
[최적 후보 탐색]if (temp_similarity > max_similarity):max_similarity = temp_similaritybest_card_to_cut = C
[최종 결정 및 덱 업데이트]
V_current[best_card_to_cut] -= 1 (시뮬레이션 결과가 가장 좋았던 카드를 '실제로' 제거)
cards_to_cut -= 1('제거 후보군' 업데이트 - 방금 0장이 된 카드는 후보에서 제외)
[결과 반환]V_final = V_current (최종 40장 덱 완성)
3. '교체 후보' 선정: 
<head></head>
### 1. 이론: '교체 후보'란 무엇인가?

우리의 '점진적 휴리스틱' 알고리즘은 **"덱 전체의 '방향성'을 가장 잘 유지하는"** 40장(`V_final`)을 이미 선정했습니다.

- **'뺄만한 카드' (선택칸 $\rightarrow$ 아웃):** `V_final`(40장)에 포함된 카드 중, 제거하더라도 `Cosine_Similarity`를 **가장 적게 훼손하거나 오히려 개선하는** 카드입니다. (즉, '가장 유연한' 카드)
- **'넣을 만한 카드' (아웃 $\rightarrow$ 선택칸):** `V_final`에 포함되지 않았거나 적게 포함된 카드 중, 추가했을 때 `Cosine_Similarity`를 **가장 많이 개선하는** 카드입니다. (즉, '가장 잠재력 있는' 카드)

* * *

### ⚙️ 2. 로직 설계: '뺄만한 카드' (Cards to Remove)

`V_final`(40장 덱)이 완성된 직후, "만약 39장으로 줄여야 한다면 어떤 카드를 빼는 것이 최선인가?"라는 시뮬레이션을 통해 순위를 매깁니다.

1. **[후보군 식별]**

    - `V_final`에서 `final_count > 0` (1장이라도 채용된) 모든 카드를 '제거 후보군'으로 설정합니다.
2. **[시뮬레이션 및 랭킹]**

    - `removable_candidates = []` (빈 리스트 생성)
    - **[Loop: '제거 후보군'의 모든 카드 `C`에 대해 시뮬레이션]**

        - `V_temp = V_final.copy()`
        - `V_temp[C] -= 1` (C번 카드를 1장 '임시로' 제거)
        - `V_temp_delta = V_temp - V_avg` (임시 델타 벡터 계산)
        - `temp_similarity = Cosine_Similarity(V_temp_delta, V_std_dev)`
        - `removable_candidates.append( {'name': C.name, 'score': temp_similarity} )`
3. **[결과]**

    - `removable_candidates` 리스트를 `score` (코사인 유사도) 기준으로 **내림차순 (High to Low)** 정렬합니다.
    - \*\*리스트의 최상단(Score 1위)\*\*에 있는 카드가 "제거하더라도 덱의 '방향성'을 가장 잘 유지하는(혹은 개선하는) 카드", 즉 \*\*'가장 뺄만한 카드 1순위'\*\*입니다.

* * *

### ⚙️ 3. 로직 설계: '대신 넣을 만한 카드' (Cards to Add)

반대로, "만약 41장으로 늘려야 한다면 어떤 카드를 넣는 것이 최선인가?"라는 시뮬레이션을 통해 순위를 매깁니다.

1. **[후보군 식별]**

    - `V_final`에서 `final_count < 3` (최대 매수(3장)를 채우지 않은) 모든 카드를 '추가 후보군'으로 설정합니다.
    - *(이래야 `final_count == 0`인 카드뿐만 아니라, `final_count == 1` 또는 `2`인 카드를 1장 '더' 넣는 것도 고려할 수 있습니다.)*
2. **[시뮬레이션 및 랭킹]**

    - `addable_candidates = []` (빈 리스트 생성)
    - **[Loop: '추가 후보군'의 모든 카드 `C`에 대해 시뮬레이션]**

        - `V_temp = V_final.copy()`
        - `V_temp[C] += 1` (C번 카드를 1장 '임시로' 추가)
        - `V_temp_delta = V_temp - V_avg` (임시 델타 벡터 계산)
        - `temp_similarity = Cosine_Similarity(V_temp_delta, V_std_dev)`
        - `addable_candidates.append( {'name': C.name, 'score': temp_similarity} )`
3. **[결과]**

    - `addable_candidates` 리스트를 `score` (코사인 유사도) 기준으로 **내림차순 (High to Low)** 정렬합니다.
    - \*\*리스트의 최상단(Score 1위)\*\*에 있는 카드가 "추가했을 때 덱의 '방향성'을 가장 개선하는 카드", 즉 \*\*'가장 넣을 만한 카드 1순위'\*\*입니다.